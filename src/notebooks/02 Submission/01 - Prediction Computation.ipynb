{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Final Prediction Computation\n",
    "\n",
    "This notebook generates the final model predictions and formats them for submission on Codabench. \n",
    "\n",
    "The evaluation dataset comprises data from 39 stations included in the training set and 13 stations exclusive to the evaluation set.\n",
    "\n",
    "<img src=\"../images/notebook-4.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n",
    "\n",
    "\n",
    "### 1. Imports\n",
    "Starts by importing the necessary libraries, configuring environment paths, and loading custom utility functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..','..','..')))\n",
    "\n",
    "from src.utils.model import load_models_auto\n",
    "from src.utils.analysis import create_predict_function, create_quantile_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines constants :\n",
    "* *DATASET_DIR* must be the directory where you unzip the *zenodo* dataset.\n",
    "* *EVAL_DIR* will be used to store inference / evaluation data it must be the same as the one defined in *01 Training > 01 - Modelisation* \n",
    "* *FINAL_MODEL* will be used to store inference / evaluation data\n",
    "\n",
    "FINAL_MODEL describe the model that will be loaded if you use auto-loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.1\n",
    "NUMBER_OF_WEEK = 4\n",
    "USE_AUTO_SCAN = True  # Toggle this to switch between the loading of the last model of the manual load of a specific model\n",
    "FINAL_MODEL = \"qrf\"\n",
    "MODEL_DIR = \"../../../models/\"\n",
    "EVAL_DIR = \"../../../data/evaluation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and models Loading\n",
    "\n",
    "Loading of the inference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "inference_data = pd.read_csv(f\"{EVAL_DIR}dataset_baseline.csv\")\n",
    "inference_data = inference_data.set_index(\"ObsDate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models based on conditions\n",
    "final_models = []\n",
    "if FINAL_MODEL == \"mapie\":\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"mapie_quantile\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-04_week0.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-11_week1.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week2.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week3.pkl\"))\n",
    "elif FINAL_MODEL == \"qrf\":\n",
    "\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"qrf_quantile\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\"))\n",
    "elif FINAL_MODEL == \"ebm\":\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"ebm_ensemble\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/EBM_ensemble_2025-01-17_15-15-04_week0.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/EBM_ensemble_2025-01-17_15-15-11_week1.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/EBM_ensemble_2025-01-17_15-15-17_week2.pkl\"))\n",
    "        final_models.append(joblib.load(f\"{MODEL_DIR}final/EBM_ensemble_2025-01-17_15-15-17_week3.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predictions computation\n",
    "\n",
    "Evaluation data include a spatio-temporal split and a temporal only split.\n",
    "\n",
    "<img src=\"../images/eval.png\" alt=\"Experiment Diagram\" style=\"width:50%;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inference_data[['station_code']].copy()\n",
    "y_pred_test_quantile = {}\n",
    "y_pred_test = {}\n",
    "X_test = inference_data.drop(columns=['station_code'])\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "    \n",
    "    if FINAL_MODEL == \"qrf\":\n",
    "        # reorder the columns\n",
    "        X_test = X_test[final_models[0].feature_names_in_]\n",
    "    predict_adjusted = create_predict_function(final_models, i, FINAL_MODEL)\n",
    "    quantile_adjusted = create_quantile_function(final_models, i, FINAL_MODEL, ALPHA)\n",
    "    \n",
    "    y_pred_test[i] = predict_adjusted(X_test)\n",
    "    y_pred_test_quantile[i] = quantile_adjusted(X_test)\n",
    "\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "    predictions[f\"week_{i}_pred\"] = y_pred_test[i]\n",
    "    predictions[f\"week_{i}_inf\"] = y_pred_test_quantile[i][:,0]\n",
    "    predictions[f\"week_{i}_sup\"] = y_pred_test_quantile[i][:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>week_0_pred</th>\n",
       "      <th>week_0_inf</th>\n",
       "      <th>week_0_sup</th>\n",
       "      <th>week_1_pred</th>\n",
       "      <th>week_1_inf</th>\n",
       "      <th>week_1_sup</th>\n",
       "      <th>week_2_pred</th>\n",
       "      <th>week_2_inf</th>\n",
       "      <th>week_2_sup</th>\n",
       "      <th>week_3_pred</th>\n",
       "      <th>week_3_inf</th>\n",
       "      <th>week_3_sup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ObsDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>5.679373e+07</td>\n",
       "      <td>46.607143</td>\n",
       "      <td>25.425293</td>\n",
       "      <td>140.431892</td>\n",
       "      <td>49.478214</td>\n",
       "      <td>19.000960</td>\n",
       "      <td>146.523571</td>\n",
       "      <td>33.429471</td>\n",
       "      <td>7.191143</td>\n",
       "      <td>129.019286</td>\n",
       "      <td>21.364286</td>\n",
       "      <td>4.902929</td>\n",
       "      <td>49.041001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-25</th>\n",
       "      <td>5.679373e+07</td>\n",
       "      <td>17.164286</td>\n",
       "      <td>5.513995</td>\n",
       "      <td>54.118815</td>\n",
       "      <td>17.060807</td>\n",
       "      <td>3.731429</td>\n",
       "      <td>60.694446</td>\n",
       "      <td>12.140957</td>\n",
       "      <td>2.942714</td>\n",
       "      <td>36.012857</td>\n",
       "      <td>10.626250</td>\n",
       "      <td>2.039071</td>\n",
       "      <td>46.919813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-07-18</th>\n",
       "      <td>5.679373e+07</td>\n",
       "      <td>18.203707</td>\n",
       "      <td>7.444429</td>\n",
       "      <td>44.158768</td>\n",
       "      <td>16.545000</td>\n",
       "      <td>4.499286</td>\n",
       "      <td>51.915000</td>\n",
       "      <td>12.140957</td>\n",
       "      <td>2.942714</td>\n",
       "      <td>43.912857</td>\n",
       "      <td>10.626250</td>\n",
       "      <td>2.039071</td>\n",
       "      <td>38.624318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-10</th>\n",
       "      <td>5.679373e+07</td>\n",
       "      <td>1.223571</td>\n",
       "      <td>0.111543</td>\n",
       "      <td>14.824929</td>\n",
       "      <td>1.845714</td>\n",
       "      <td>0.103314</td>\n",
       "      <td>11.189429</td>\n",
       "      <td>4.253571</td>\n",
       "      <td>0.284443</td>\n",
       "      <td>29.028548</td>\n",
       "      <td>4.883571</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>26.063571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-02</th>\n",
       "      <td>5.679373e+07</td>\n",
       "      <td>18.203707</td>\n",
       "      <td>7.444429</td>\n",
       "      <td>44.158768</td>\n",
       "      <td>16.625093</td>\n",
       "      <td>4.499286</td>\n",
       "      <td>51.915000</td>\n",
       "      <td>12.140957</td>\n",
       "      <td>2.942714</td>\n",
       "      <td>43.912857</td>\n",
       "      <td>15.397114</td>\n",
       "      <td>2.411143</td>\n",
       "      <td>48.939004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station_code  week_0_pred  week_0_inf  week_0_sup  week_1_pred  \\\n",
       "ObsDate                                                                      \n",
       "2004-02-01  5.679373e+07    46.607143   25.425293  140.431892    49.478214   \n",
       "2004-04-25  5.679373e+07    17.164286    5.513995   54.118815    17.060807   \n",
       "2004-07-18  5.679373e+07    18.203707    7.444429   44.158768    16.545000   \n",
       "2004-10-10  5.679373e+07     1.223571    0.111543   14.824929     1.845714   \n",
       "2005-01-02  5.679373e+07    18.203707    7.444429   44.158768    16.625093   \n",
       "\n",
       "            week_1_inf  week_1_sup  week_2_pred  week_2_inf  week_2_sup  \\\n",
       "ObsDate                                                                   \n",
       "2004-02-01   19.000960  146.523571    33.429471    7.191143  129.019286   \n",
       "2004-04-25    3.731429   60.694446    12.140957    2.942714   36.012857   \n",
       "2004-07-18    4.499286   51.915000    12.140957    2.942714   43.912857   \n",
       "2004-10-10    0.103314   11.189429     4.253571    0.284443   29.028548   \n",
       "2005-01-02    4.499286   51.915000    12.140957    2.942714   43.912857   \n",
       "\n",
       "            week_3_pred  week_3_inf  week_3_sup  \n",
       "ObsDate                                          \n",
       "2004-02-01    21.364286    4.902929   49.041001  \n",
       "2004-04-25    10.626250    2.039071   46.919813  \n",
       "2004-07-18    10.626250    2.039071   38.624318  \n",
       "2004-10-10     4.883571    0.900200   26.063571  \n",
       "2005-01-02    15.397114    2.411143   48.939004  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Saving of the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving of the predictions as a csv file\n",
    "\n",
    "> The file must be named `predictions.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gk/repos/Hackathon-Water-Scarcity/src/notebooks/02 Submission'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to a csv file\n",
    "predictions.station_code = predictions.station_code.astype(int)\n",
    "predictions[\"ObsDate\"] = X_test.index\n",
    "predictions.to_csv(f\"{EVAL_DIR}predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>week_0_pred</th>\n",
       "      <th>week_0_inf</th>\n",
       "      <th>week_0_sup</th>\n",
       "      <th>week_1_pred</th>\n",
       "      <th>week_1_inf</th>\n",
       "      <th>week_1_sup</th>\n",
       "      <th>week_2_pred</th>\n",
       "      <th>week_2_inf</th>\n",
       "      <th>week_2_sup</th>\n",
       "      <th>week_3_pred</th>\n",
       "      <th>week_3_inf</th>\n",
       "      <th>week_3_sup</th>\n",
       "      <th>ObsDate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ObsDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-01</th>\n",
       "      <td>56793730</td>\n",
       "      <td>46.607143</td>\n",
       "      <td>25.425293</td>\n",
       "      <td>140.431892</td>\n",
       "      <td>49.478214</td>\n",
       "      <td>19.000960</td>\n",
       "      <td>146.523571</td>\n",
       "      <td>33.429471</td>\n",
       "      <td>7.191143</td>\n",
       "      <td>129.019286</td>\n",
       "      <td>21.364286</td>\n",
       "      <td>4.902929</td>\n",
       "      <td>49.041001</td>\n",
       "      <td>2004-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-25</th>\n",
       "      <td>56793730</td>\n",
       "      <td>17.164286</td>\n",
       "      <td>5.513995</td>\n",
       "      <td>54.118815</td>\n",
       "      <td>17.060807</td>\n",
       "      <td>3.731429</td>\n",
       "      <td>60.694446</td>\n",
       "      <td>12.140957</td>\n",
       "      <td>2.942714</td>\n",
       "      <td>36.012857</td>\n",
       "      <td>10.626250</td>\n",
       "      <td>2.039071</td>\n",
       "      <td>46.919813</td>\n",
       "      <td>2004-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station_code  week_0_pred  week_0_inf  week_0_sup  week_1_pred  \\\n",
       "ObsDate                                                                      \n",
       "2004-02-01      56793730    46.607143   25.425293  140.431892    49.478214   \n",
       "2004-04-25      56793730    17.164286    5.513995   54.118815    17.060807   \n",
       "\n",
       "            week_1_inf  week_1_sup  week_2_pred  week_2_inf  week_2_sup  \\\n",
       "ObsDate                                                                   \n",
       "2004-02-01   19.000960  146.523571    33.429471    7.191143  129.019286   \n",
       "2004-04-25    3.731429   60.694446    12.140957    2.942714   36.012857   \n",
       "\n",
       "            week_3_pred  week_3_inf  week_3_sup     ObsDate  \n",
       "ObsDate                                                      \n",
       "2004-02-01    21.364286    4.902929   49.041001  2004-02-01  \n",
       "2004-04-25    10.626250    2.039071   46.919813  2004-04-25  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression of the submission file.\n",
    "\n",
    "> The file need to be compress for Codabench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP file containing predictions.csv\n",
    "with zipfile.ZipFile(f\"{EVAL_DIR}predictions.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(f\"{EVAL_DIR}predictions.csv\", \"predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to submit go to codabench and submit the zip file that have been generated in My Submissions > Phase 1.\n",
    "\n",
    "\n",
    "You don't have to use this notebook to submit but the file file format must includes the following columns:\n",
    "* station_code: Identification code of the station.\n",
    "* ObsDate: Date of the prediction.\n",
    "* for every week of prediction i from 0 to 3 :\n",
    "    * week_i_pred\n",
    "    * week_i_inf\n",
    "    * week_i_sup\n",
    "\n",
    "\n",
    "Save the dataset as a CSV file named predictions.csv. \n",
    "> The file must be named predictions.csv, but the .zip file can have any name.\n",
    "\n",
    "\n",
    "Compress the CSV file into a .zip archive. \n",
    "> You cannot submit an uncompressed file. Ensure that the software you use does not create a subfolder inside the archive.\n",
    "\n",
    "\n",
    "Submit your file in [Codabench](https://www.codabench.org/competitions/4335): \n",
    "> My Submissions > Phase 1 (keep all the tasks selected):\n",
    "\n",
    "<img src=\"../images/submissions.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
